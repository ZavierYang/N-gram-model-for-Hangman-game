{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hangman Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        This function plays the hangman game with the provided guesser and returns the number of incorrect guesses. \n",
    "        \n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of number of allowed mistakes\n",
    "        verbose: silent or verbose diagnostic prints\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word and len(guess) == 1:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if len(guess) != 1:\n",
    "                    print('Please guess with only 1 character.')\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a human guesser allowing interactive play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    This is a simple function for manual play.\n",
    "    \"\"\"\n",
    "    print('\\nEnter your guess:')\n",
    "    return input().lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to play hangman interactively, please set `interactive` to `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>\n",
    "\n",
    "You can play the game interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interactive:\n",
    "    hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pre-processing\n",
    "Use NLTK's Brown corpus for training an artificial intelligence guessing algorithm, and for evaluating the quality of the algorithm.\n",
    "\n",
    "1. compute the number of **unique word types** occurring in the Brown corpus, using `nltk.corpus.brown` and the `words` method, and select only words that are **entirely comprised of alphabetic characters**. \n",
    "\n",
    "2. **Lowercase the words**. \n",
    "\n",
    "3. Finally, randomly shuffle (`numpy.random.shuffle`) this collection of word types, and split them into disjoint training and testing sets. Both `training_set` and `test_set` should be a python `list`. Besides, `test_set` should contain 1000 word types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word types in test = 1000\n",
      "Number of word types in train = 39234\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# training_set stores the rest word types for training\n",
    "training_set = []\n",
    "# test_set stores 1000 word types for testing\n",
    "test_set = []\n",
    "\n",
    "#words from brown corpus\n",
    "brown_words = brown.words()\n",
    "\n",
    "#lowercase the corpus and remove the word which contain non-alphabetic characters\n",
    "processed_words = []\n",
    "for word in brown_words:\n",
    "    if word.isalpha():\n",
    "        processed_words.append(word.lower())\n",
    "\n",
    "#unique words in brown corpus\n",
    "unique_words = list(set(processed_words))\n",
    "\n",
    "# change to array in order to conduct np shuffle, then convert to list\n",
    "unique_words = np.array(unique_words)\n",
    "np.random.shuffle(unique_words)\n",
    "unique_words = unique_words.tolist()\n",
    "\n",
    "test_set = unique_words[:1000]\n",
    "training_set = unique_words[1000:]\n",
    "\n",
    "print(\"Number of word types in test =\", len(test_set))\n",
    "print(\"Number of word types in train =\", len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play the game by yourself. Make sure that `interactive` = True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play hangman using random words from test set\n",
    "if interactive:\n",
    "    hangman(np.random.choice(test_set), human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Method\n",
    "\n",
    "Baseline is a trivial **random method**. The method should randomly choose a character from the range `a ... z` after excluding the characters that have already been guessed in the current game (all subsequent AI approaches should also exclude previous guesses).\n",
    "\n",
    "`test_guesser` method that takes a guesser and measures the average number of incorrect guesses made over all the words in the `test_set` is provided to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_guesser(guesser, test=test_set):\n",
    "    total = 0\n",
    "    for word in test:\n",
    "        total += hangman(word, guesser, 26, False)\n",
    "    return total / float(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing word = newt\n",
      "Number of mistakes made by the random guesser = 19\n",
      "\n",
      "Testing the random guesser using every word in test set\n",
      "Average number of incorrect guesses:  16.728\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def random_guesser(mask, guessed, **kwargs):\n",
    "    \n",
    "    # available is a list that does not contain the character in guessed\n",
    "    available = set(string.ascii_lowercase) - guessed\n",
    "    return random.choice(list(available))\n",
    "\n",
    "random_word = np.random.choice(test_set)\n",
    "print(\"Guessing word =\", random_word)\n",
    "print(\"Number of mistakes made by the random guesser =\", hangman(random_word, random_guesser, 26, False))\n",
    "\n",
    "result = test_guesser(random_guesser)\n",
    "print(\"\\nTesting the random guesser using every word in test set\")\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Language Model\n",
    "\n",
    "The first real AI is a **unigram language model** over the training set. This requires to find the frequencies of characters over all training words. A guesser should returns the character with the highest probability. Remember to exclude already guessed characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = None\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Build unigram model. Count character frequency.\n",
    "def unigram(corpus):\n",
    "    unigram_counts = Counter()\n",
    "    \n",
    "    for word in corpus:\n",
    "        for char in word:\n",
    "            unigram_counts[char] += 1\n",
    "            \n",
    "    return unigram_counts\n",
    "\n",
    "unigram_counts = unigram(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the unigram guesser using every word in test set\n",
      "Average number of incorrect guesses:  10.484\n"
     ]
    }
   ],
   "source": [
    "def unigram_guesser(mask, guessed, unigram_counts=unigram_counts):\n",
    "\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    copy_dict = unigram_counts.copy() \n",
    "    \n",
    "    # Delete the guessed word first, then take the max value in the dictionary\n",
    "    for char in guessed:\n",
    "        del copy_dict[char]\n",
    "\n",
    "    return max(copy_dict, key=copy_dict.get)\n",
    "\n",
    "result = test_guesser(unigram_guesser)\n",
    "print(\"Testing the unigram guesser using every word in test set\")\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Based on Word Length\n",
    "\n",
    "The length of the secret word is an important clue that we might exploit. Different lengths tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. Incorporate this idea by conditioning the unigram model on the length of the secret word, i.e.,  having a **different unigram model for each length**. \n",
    "\n",
    "When encounter an unseen word length, the method should behave like the previous `unigram_guesser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unigram_counts_by_length = None\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "def unigram_length(corpus):\n",
    "    #This allow all values are counters\n",
    "    unigram_counts = defaultdict(Counter)\n",
    "    \n",
    "    for word in corpus:\n",
    "        length = len(word)\n",
    "        for char in word:\n",
    "            #index will be[word's length][character]\n",
    "            unigram_counts[length][char] += 1\n",
    "            \n",
    "    return unigram_counts\n",
    "\n",
    "unigram_counts_by_length = unigram_length(training_set)\n",
    "\n",
    "###############################################################################################################################\n",
    "# Add the unseen character for each length to zero in order to avoid max() has no element to pick, since this algo will delete#\n",
    "# element in dictionary and take max value of it. If we encounter unseen pattern, max() will have error with no arguement.    #\n",
    "###############################################################################################################################\n",
    "\n",
    "for key in unigram_counts_by_length.keys():\n",
    "    if not len(unigram_counts_by_length[key]) == 26:\n",
    "        add_char = set(string.ascii_lowercase) - set(list(unigram_counts_by_length[key].keys()))\n",
    "    \n",
    "        for char in add_char:\n",
    "            unigram_counts_by_length[key][char] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the length-conditioned unigram guesser using every word in test set\n",
      "Average number of incorrect guesses:  10.443\n"
     ]
    }
   ],
   "source": [
    "def unigram_length_guesser(mask, guessed, unigram_counts_by_length=unigram_counts_by_length, unigram_counts=unigram_counts):\n",
    "\n",
    "    if len(mask) not in list(unigram_counts_by_length.keys()):\n",
    "        return unigram_guesser(mask, guessed, unigram_counts)\n",
    "    else:\n",
    "        copy_dict = unigram_counts_by_length[len(mask)].copy() \n",
    "        \n",
    "        #remove the guessed characters in copy_dict and then return the max frequency character.\n",
    "        for char in guessed:\n",
    "            del copy_dict[char]\n",
    "        \n",
    "        return max(copy_dict, key=copy_dict.get)\n",
    "\n",
    "    \n",
    "result = test_guesser(unigram_length_guesser)\n",
    "print(\"Testing the length-conditioned unigram guesser using every word in test set\")\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Language Model\n",
    "\n",
    "Now build a **bigram language model** over characters, and train it over the training words. The order of characters is important. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly, the distribution over characters that start or end a word are highly biased.\n",
    "\n",
    "**Bigram guesser should apply language model to each blank position in the secret word by using its left context character.**\n",
    "\n",
    "For example, `e _ c _ b _ _` , \n",
    "\n",
    "The left context for the first three blanks, but have no known left context for the last blank. In the case for the last blank, revert to using a unigram language model. We need sum up the probability distribution (over all alphabets from a to z) for the 4 blanks, and select the alphabet with the highest probability that hasn't been guessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = None\n",
    "\n",
    "# add $ to the front of a word since this is a Bigram Model.\n",
    "def convert_word(word):\n",
    "    return \"$\" + word\n",
    "\n",
    "# Collect bigram counts. Because we don't delete keys in dictionary and counter will return 0 for unseen pattern,\n",
    "# we don't need to add char for dictionary as Unigram Based on Word Length approach.\n",
    "def bigram(corpus):\n",
    "    bigram_counts = defaultdict(Counter)\n",
    "    \n",
    "    for word in corpus:\n",
    "        word = convert_word(word)\n",
    "        \n",
    "        # generate a list of bigrams\n",
    "        bigram_list = zip(word[:-1], word[1:])\n",
    "        \n",
    "        # iterate over bigrams\n",
    "        for bigram in bigram_list:\n",
    "            first, second = bigram\n",
    "            bigram_counts[first][second] += 1\n",
    "    return bigram_counts\n",
    "    \n",
    "bigram_counts = bigram(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bigram probability\n",
    "def bigram_prob(key, char, bigram_counts):\n",
    "    prev_word_counts = bigram_counts[key]\n",
    "    total_counts = float(sum(prev_word_counts.values()))\n",
    "\n",
    "    return prev_word_counts[char] / float(sum(prev_word_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the bigram guesser using every word in test set\n",
      "Average number of incorrect guesses:  8.641\n"
     ]
    }
   ],
   "source": [
    "def bigram_guesser(mask, guessed, bigram_counts=bigram_counts, unigram_counts=unigram_counts): # add extra arguments if needed\n",
    "    \n",
    "    # available is a list that does not contain the character in guessed\n",
    "    available = list(set(string.ascii_lowercase) - guessed)\n",
    "    \n",
    "    # The probabilities of available character\n",
    "    bigram_probs = []\n",
    "    \n",
    "    for char in available:\n",
    "        char_prob = 0\n",
    "        for index in range(len(mask)):\n",
    "            # The first case is that the first char has not been guessed\n",
    "            if index == 0 and mask[index] == '_':\n",
    "                char_prob +=  bigram_prob('$', char, bigram_counts)\n",
    "                \n",
    "            # The second case is that the other chars have not been guessed\n",
    "            elif mask[index] == '_':\n",
    "                # if the previous word has been guessed apply bigram\n",
    "                if not mask[index - 1] == '_':\n",
    "                    char_prob +=  bigram_prob(mask[index - 1], char, bigram_counts)\n",
    "                    \n",
    "                # If the previous word has not been guessed apply unigram\n",
    "                else:\n",
    "                    char_prob +=  unigram_counts[char] / float(sum(unigram_counts.values()))\n",
    "                \n",
    "            # The final case is that the character is guessed so we skip this position\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        bigram_probs.append(char_prob)\n",
    "    \n",
    "    # Return the max probability of char\n",
    "    return available[bigram_probs.index(max(bigram_probs))]\n",
    "\n",
    "result = test_guesser(bigram_guesser)\n",
    "print(\"Testing the bigram guesser using every word in test set\")\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Model with Smoothing Method\n",
    "\n",
    "1. Pad \\$\\$ to the front of the words\n",
    "2. Get the unigram, bigram and trigram count from training set\n",
    "3. Apply trigram model to each blank position in the secret word by using its left 2 context characters\n",
    "4. We need to apply trigram, bigram and unigram based on different situations.\n",
    "    - For the first character\n",
    "        - \\$\\$_ : apply trigram for the blank\n",
    "    - For the second character\n",
    "        - \\$a\\_ : apply trigram for the blank\n",
    "        - \\$\\_ \\_: apply unigram for the last blank, since we cannot apply bigram and trigram.\n",
    "    - For the other position words\n",
    "        - aa_: apply trigram for the blank\n",
    "        - \\_a\\_: apply bigram for the last blank, since we cannot apply trigram\n",
    "        - a\\_ \\_: apply unigram for the last blank, since we cannot apply bigram and trigram\n",
    "5. Apply interpolation smoothing method. \n",
    "    - For trigram probability, multiply 0.6\n",
    "    - For bigram probability, multiply 0.3\n",
    "    - For unigram probability, multiply 0.1\n",
    "6. Sum up the probability distribution (over all alphabets from a to z) for every blank.\n",
    "7. Take the max probability of the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add $$ to the front of a word\n",
    "def trigram_convert_word(word):\n",
    "    return \"$$\" + word\n",
    "\n",
    "# collect trigram counts\n",
    "def trigram(corpus):\n",
    "    trigram_counts = Counter()\n",
    "    bigram_counts = defaultdict(Counter)\n",
    "    \n",
    "    for word in corpus:\n",
    "        word = trigram_convert_word(word)\n",
    "        \n",
    "        # generate a list of trigrams\n",
    "        trigram_list = zip(word[:-2], word[1:-1], word[2:])\n",
    "        \n",
    "        # generate a list of bigrams\n",
    "        bigram_list = zip(word[:-1], word[1:])\n",
    "        \n",
    "        # iterate over trigrams\n",
    "        for trigram in trigram_list:\n",
    "            first, second, third = trigram\n",
    "            element = first+second+third\n",
    "            trigram_counts[element] += 1\n",
    "            \n",
    "        # iterate over bigrams\n",
    "        for bigram in bigram_list:\n",
    "            first, second = bigram\n",
    "            bigram_counts[first][second] += 1\n",
    "            \n",
    "    return trigram_counts, bigram_counts\n",
    "    \n",
    "trigram_counts, bigram_counts_for_trigram = trigram(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trigram probability\n",
    "def trigram_prob(wi_2, wi_1, char, trigram_counts, bigram_counts):\n",
    "    return trigram_counts[wi_2 + wi_1 + char] / float(bigram_counts[wi_2][wi_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing my amazing AI guesser using every word in test set\n",
      "Average number of incorrect guesses:  8.102\n"
     ]
    }
   ],
   "source": [
    "def my_amazing_ai_guesser(mask, guessed, bigram_counts=bigram_counts_for_trigram, trigram_counts=trigram_counts, \n",
    "                          unigram_counts=unigram_counts):\n",
    "    \n",
    "    # available is a list that does not contain the character in guessed\n",
    "    available = list(set(string.ascii_lowercase) - guessed)\n",
    "\n",
    "    # The probabilities of available character\n",
    "    trigram_probs = []\n",
    "    \n",
    "    # if len(mask) = 1, means that there is only a character. Therefore, need to pad in order to avoid error from \n",
    "    # traverse mask[index -2] and mask[index -1] \n",
    "    mask = ['$', '$'] + mask\n",
    "    \n",
    "    trigram_lambda = 0.6\n",
    "    bigram_lambda = 0.3\n",
    "    unigram_lambda = 0.1\n",
    "    \n",
    "    for char in available:\n",
    "        char_prob = 0\n",
    "        for index in range(len(mask)):\n",
    "            # The first case is that the first char has not been guessed\n",
    "            if index == 0 and mask[index] == '_':\n",
    "                char_prob += trigram_lambda * trigram_prob('$', '$', char, trigram_counts, bigram_counts)\n",
    "                \n",
    "            # The second case is that the second char has not been guessed\n",
    "            if index == 1 and mask[index] == '_':\n",
    "                # If the previous word has been guessed, apply trigram\n",
    "                if not mask[index - 1] == '_':\n",
    "                    char_prob += trigram_lambda * trigram_prob('$', mask[index - 1], char, trigram_counts, bigram_counts)\n",
    "                    \n",
    "                # If the previous word has not been guessed, apply unigram\n",
    "                else:\n",
    "                    char_prob +=  unigram_lambda * unigram_counts[char] / float(sum(unigram_counts.values()))\n",
    "            \n",
    "            # The third case is that the other chars have not been guessed\n",
    "            elif mask[index] == '_':\n",
    "                # If wi-2 and wi-1 have been guessed, apply trigram\n",
    "                if not mask[index - 2] == '_' and not mask[index - 1] == '_':\n",
    "                    char_prob += trigram_lambda * trigram_prob(mask[index - 2], mask[index - 1], char, \n",
    "                                                            trigram_counts, bigram_counts)\n",
    "                    \n",
    "                # If wi-2 hasn't been guessed but wi-1 has been guessed, apply bigram\n",
    "                elif mask[index - 2] == '_' and not mask[index - 1] == '_':\n",
    "                    char_prob += bigram_lambda * bigram_prob(mask[index - 1], char, bigram_counts)\n",
    "                \n",
    "                # If wi-1 hasn't been guessed, apply unigram\n",
    "                else:\n",
    "                    char_prob +=  unigram_lambda * unigram_counts[char] / float(sum(unigram_counts.values()))\n",
    "                \n",
    "            # The final case is that the character is guessed so we skip this position\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        trigram_probs.append(char_prob)\n",
    "    \n",
    "    # Return the max probability of char\n",
    "    return available[trigram_probs.index(max(trigram_probs))]\n",
    "\n",
    "result = test_guesser(my_amazing_ai_guesser)\n",
    "print(\"Testing my amazing AI guesser using every word in test set\")\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
